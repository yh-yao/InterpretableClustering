{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0xIpO0PguRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4b110c-93d4-4631-d099-d1da3dc9ee5a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGqiJhfUbxiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef0e98a-e26a-408b-fcfd-7590fe0f7241"
      },
      "source": [
        "%cd drive/My Drive/Interpretable-RNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/Interpretable-RNN'\n",
            "/content/drive/My Drive/Interpretable-RNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klW8f75pnfHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "239c87a4-08a0-42f3-aed4-78eb756b64b7"
      },
      "source": [
        "%cd dblp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Interpretable-RNN/dblp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMeR_uUzdooO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc44898-3afa-4928-a3e3-a06a60f7fd3f"
      },
      "source": [
        "!wget https://lfs.aminer.cn/misc/dblp.v11.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-31 20:06:02--  https://lfs.aminer.cn/misc/dblp.v11.zip\n",
            "Resolving lfs.aminer.cn (lfs.aminer.cn)... 40.73.3.16\n",
            "Connecting to lfs.aminer.cn (lfs.aminer.cn)|40.73.3.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3922056320 (3.7G) [application/zip]\n",
            "Saving to: ‘dblp.v11.zip’\n",
            "\n",
            "dblp.v11.zip        100%[===================>]   3.65G  35.0MB/s    in 87s     \n",
            "\n",
            "2021-10-31 20:07:30 (42.8 MB/s) - ‘dblp.v11.zip’ saved [3922056320/3922056320]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gt65xDI-ijr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b041210-e728-43c2-f78f-fba84a2eb59a"
      },
      "source": [
        "!unzip dblp.v11.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dblp.v11.zip\n",
            "  inflating: dblp_papers_v11.txt     "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNbroxCJo3AA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "c46ddee2-8001-49a6-8bb0-20e6e1425eee"
      },
      "source": [
        "import json\n",
        "a=open(\"dblp_papers_v11.txt\",\"r\")\n",
        "b=open(\"dblp_author_fos_year.txt\",'w')\n",
        "for line in a:\n",
        "    c=json.loads(line)\n",
        "    try:\n",
        "    #for zz in range(1):\n",
        "        for i in (c['authors']):\n",
        "\n",
        "            for j in (c['fos']):\n",
        "                b.write(i['id']+'\\t'+j['name']+'\\t'+str(c['year'])+'\\n')\n",
        "    except:\n",
        "        zz=1\n",
        "a.close()\n",
        "b.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f7d80d7ae3d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dblp_papers_v11.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dblp_author_fos_year.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dblp_papers_v11.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4SU9JUFbvQd"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTqFCrpIBPaq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4b92c5d7-bc12-4355-f816-042c54239aee"
      },
      "source": [
        "import json\n",
        "a=open(\"dblp_papers_v11.txt\",\"r\")\n",
        "\n",
        "for line in a:\n",
        "    c=json.loads(line)\n",
        "    try:\n",
        "    #for zz in range(1):\n",
        "        print(c)\n",
        "        for i in (c['authors']):\n",
        "            if(i['id']=='2107438709'):\n",
        "              print(1)\n",
        "              print(i['name'])\n",
        "\n",
        "            break\n",
        "        break\n",
        "    except:\n",
        "      zz=1\n",
        "a.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'id': '100001334', 'title': 'Ontologies in HYDRA - Middleware for Ambient Intelligent Devices.', 'authors': [{'name': 'Peter Kostelnik', 'id': '2702511795'}, {'name': 'Martin Sarnovsky', 'id': '2041014688'}, {'name': 'Jan Hreno', 'id': '2398560122'}], 'venue': {'raw': 'AMIF'}, 'year': 2009, 'n_citation': 2, 'page_start': '43', 'page_end': '46', 'doc_type': '', 'publisher': '', 'volume': '', 'issue': '', 'fos': [{'name': 'Lernaean Hydra', 'w': 0.4178039}, {'name': 'Database', 'w': 0.4269269}, {'name': 'World Wide Web', 'w': 0.415332377}, {'name': 'Ontology (information science)', 'w': 0.459045082}, {'name': 'Computer science', 'w': 0.399807781}, {'name': 'Middleware', 'w': 0.5905041}, {'name': 'Ambient intelligence', 'w': 0.5440575}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTS9iidBo3ON"
      },
      "source": [
        "a=open(\"dblp_author_fos_year.txt\",'r')\n",
        "author_num=dict()\n",
        "for line in a:\n",
        "  line=line.split('\\t')\n",
        "  if author_num.get(line[0])!=None:\n",
        "    author_num[line[0]]+=1\n",
        "  else:\n",
        "    author_num[line[0]]=1\n",
        "a.close()\n",
        "b=open('author_num_>10.txt','w')\n",
        "for i,j in author_num.items():\n",
        "  if j>10:\n",
        "    b.write(str(i)+'\\t'+str(j)+'\\n')\n",
        "b.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtCb181ky9in"
      },
      "source": [
        "b=open('author_num_>100.txt','w')\n",
        "for i,j in author_num.items():\n",
        "  if j>100:\n",
        "    b.write(str(i)+'\\t'+str(j)+'\\n')\n",
        "b.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdKv8lHy0Mgk"
      },
      "source": [
        "b=open(\"dblp_author_fos_year_>100.txt\",'w')\n",
        "a=open(\"dblp_author_fos_year.txt\",'r')\n",
        "\n",
        "for line in a:\n",
        "  tmp=line\n",
        "  line=line.split('\\t')\n",
        "  if author_num[line[0]]>100:\n",
        "    b.write(tmp)\n",
        "a.close()\n",
        "b.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIHFD44y0Mqx"
      },
      "source": [
        "from collections import Counter\n",
        "a=open(\"dblp_author_fos_year_>100.txt\",'r')\n",
        "\n",
        "author_field=dict()\n",
        "for line in a:\n",
        "  tmp=line\n",
        "  line=line.split('\\t')\n",
        "  if author_field.get(line[0])!=None:\n",
        "    author_field[line[0]]+=[(int(line[2]),tmp)]\n",
        "  else:\n",
        "    author_field[line[0]]=[(int(line[2]),tmp)]\n",
        "a.close()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EuixOWE7FoS"
      },
      "source": [
        "a=open(\"dblp_author_fos_year_>100_sort.txt\",'w')\n",
        "for i,j in author_field.items():\n",
        "  for line in sorted(j,key=lambda e:e[0]):\n",
        "    a.write(line[1])\n",
        "a.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34g2jvZxo8yO"
      },
      "source": [
        "\n",
        "a=open(\"dblp_author_fos_year_>100_sort.txt\",'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc0mleocQvMa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "6b2f8c9e-08f9-42b0-caf8-354d901456f7"
      },
      "source": [
        "a.readline()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2107438709\\tTheoretical computer science\\t1998\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNmAnjAb7_yr"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "a=open(\"dblp_author_fos_year_>100_sort.txt\",'r')\n",
        "word_a=\"Computer network\"\n",
        "word_b=\"Machine learning\"\n",
        "b=open(\"filter_\"+word_a+\"_\"+word_b+\".txt\",'w')\n",
        "count=0\n",
        "name=''\n",
        "now_year=0\n",
        "labels=[]\n",
        "for line in a:\n",
        "  tmp=line\n",
        "  line=line.split('\\t')\n",
        "  if line[0]!=name:\n",
        "      if len(labels)>0:\n",
        "        result=Counter(labels)\n",
        "        if result.get(word_a)!=None:\n",
        "          a_num=result[word_a]\n",
        "        else:\n",
        "          a_num=0\n",
        "        if result.get(word_b)!=None:\n",
        "          b_num=result[word_b]\n",
        "        else:\n",
        "          b_num=0\n",
        "        if a_num!=0 or b_num!=0:\n",
        "          b.write(name+'\\t'+str(now_year)+'\\t'+str(a_num)+'\\t'+str(b_num)+'\\t'+'\\n')\n",
        "      name=line[0]\n",
        "      labels=[line[1]]\n",
        "      now_year=int(line[2])\n",
        "  else:\n",
        "    if now_year!=int(line[2]):\n",
        "      result=Counter(labels)\n",
        "      if result.get(word_a)!=None:\n",
        "          a_num=result[word_a]\n",
        "      else:\n",
        "          a_num=0\n",
        "      if result.get(word_b)!=None:\n",
        "          b_num=result[word_b]\n",
        "      else:\n",
        "          b_num=0\n",
        "      if a_num!=0 or b_num!=0:\n",
        "        b.write(name+'\\t'+str(now_year)+'\\t'+str(a_num)+'\\t'+str(b_num)+'\\n')\n",
        "      labels=[line[1]]\n",
        "      now_year=int(line[2])\n",
        "    else:\n",
        "      labels+=[line[1]]\n",
        "  count+=1\n",
        "  #if count>3000:\n",
        "  #  break\n",
        "result=Counter(labels)\n",
        "if result.get(word_a)!=None:\n",
        "          a_num=result[word_a]\n",
        "else:\n",
        "          a_num=0\n",
        "if result.get(word_b)!=None:\n",
        "          b_num=result[word_b]\n",
        "else:\n",
        "          b_num=0\n",
        "if a_num!=0 or b_num!=0:\n",
        "  b.write(name+'\\t'+str(now_year)+'\\t'+str(a_num)+'\\t'+str(b_num)+'\\t'+'\\n')\n",
        "a.close()\n",
        "b.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsjiYESZ-ikx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEzHB4t--ik1",
        "outputId": "954c6d2d-98d7-467c-ed16-e09ba6e23114"
      },
      "source": [
        "word_a=\"Computer network\"\n",
        "word_b=\"Machine learning\"\n",
        "a=open(\"filter_\"+word_a+\"_\"+word_b+\".txt\",'r')\n",
        "\n",
        "author=None\n",
        "authors=dict()\n",
        "change_author_01=[]\n",
        "change_author_10=[]\n",
        "flag=-1\n",
        "change_author=[]\n",
        "year_count=dict()\n",
        "year_num_count=dict()\n",
        "for i in range(1950,2020):\n",
        "  year_count[str(i)]=[0,0]\n",
        "  year_num_count[str(i)]=[0,0]\n",
        "for line in a:\n",
        "  line=line.split()\n",
        "  if author!=line[0]:\n",
        "    author=line[0]\n",
        "    authors[author]=1\n",
        "    flag=-1\n",
        "  if int(line[2])<int(line[3]):\n",
        "    flag_now=1\n",
        "  elif int(line[2])>int(line[3]):\n",
        "    flag_now=0\n",
        "  else:\n",
        "    flag_now=flag\n",
        "  if flag!=-1:\n",
        "    if flag!=flag_now:\n",
        "      if flag==0:\n",
        "        change_author_01+=[line[0]]\n",
        "        year_count[line[1]][0]+=1\n",
        "      else:\n",
        "        change_author_10+=[line[0]]\n",
        "        year_count[line[1]][1]+=1 #number of changed authors in that area\n",
        "      change_author+=[line[0]]\n",
        "  flag=flag_now\n",
        "  year_num_count[line[1]][flag]+=1 #number of authors in that area\n",
        "a.close()\n",
        "\n",
        "print(len(authors),len(set(change_author)),len(set(change_author_01)),len(set(change_author_10)))\n",
        "print(year_count)\n",
        "print(year_num_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "126285 17053 13140 11204\n",
            "{'1950': [0, 0], '1951': [0, 0], '1952': [0, 0], '1953': [0, 0], '1954': [0, 0], '1955': [0, 0], '1956': [0, 0], '1957': [0, 0], '1958': [0, 0], '1959': [0, 0], '1960': [0, 0], '1961': [0, 0], '1962': [0, 0], '1963': [0, 0], '1964': [0, 0], '1965': [0, 0], '1966': [0, 0], '1967': [0, 0], '1968': [0, 0], '1969': [0, 0], '1970': [0, 0], '1971': [0, 0], '1972': [0, 0], '1973': [0, 0], '1974': [0, 0], '1975': [1, 0], '1976': [0, 1], '1977': [0, 0], '1978': [0, 2], '1979': [1, 0], '1980': [0, 0], '1981': [0, 8], '1982': [1, 2], '1983': [3, 1], '1984': [1, 5], '1985': [2, 1], '1986': [3, 8], '1987': [6, 6], '1988': [18, 2], '1989': [12, 10], '1990': [15, 10], '1991': [11, 16], '1992': [15, 17], '1993': [17, 21], '1994': [27, 48], '1995': [40, 30], '1996': [36, 54], '1997': [33, 79], '1998': [46, 78], '1999': [46, 122], '2000': [69, 130], '2001': [84, 185], '2002': [147, 207], '2003': [183, 276], '2004': [247, 324], '2005': [375, 431], '2006': [487, 529], '2007': [551, 576], '2008': [609, 633], '2009': [770, 674], '2010': [852, 766], '2011': [1004, 784], '2012': [1055, 942], '2013': [1158, 984], '2014': [1357, 1000], '2015': [1429, 985], '2016': [1530, 1030], '2017': [1491, 1152], '2018': [1405, 835], '2019': [54, 7]}\n",
            "{'1950': [0, 0], '1951': [0, 0], '1952': [0, 0], '1953': [0, 0], '1954': [0, 0], '1955': [0, 0], '1956': [0, 2], '1957': [0, 0], '1958': [0, 0], '1959': [0, 0], '1960': [0, 0], '1961': [0, 5], '1962': [0, 7], '1963': [0, 1], '1964': [0, 2], '1965': [0, 5], '1966': [0, 3], '1967': [0, 5], '1968': [1, 24], '1969': [8, 37], '1970': [2, 27], '1971': [5, 51], '1972': [0, 38], '1973': [3, 70], '1974': [5, 41], '1975': [7, 86], '1976': [12, 80], '1977': [15, 128], '1978': [19, 96], '1979': [13, 171], '1980': [18, 155], '1981': [54, 162], '1982': [49, 202], '1983': [92, 338], '1984': [131, 287], '1985': [125, 353], '1986': [212, 399], '1987': [165, 578], '1988': [192, 978], '1989': [295, 1144], '1990': [379, 1477], '1991': [434, 1710], '1992': [538, 1923], '1993': [745, 2458], '1994': [930, 2800], '1995': [1009, 3162], '1996': [1173, 3790], '1997': [1569, 3943], '1998': [1676, 4937], '1999': [2255, 5265], '2000': [3070, 6337], '2001': [3948, 6627], '2002': [5034, 7917], '2003': [6142, 9400], '2004': [7562, 11321], '2005': [9230, 13630], '2006': [10889, 15411], '2007': [12029, 17602], '2008': [13026, 18068], '2009': [14074, 20590], '2010': [14516, 22291], '2011': [15461, 24296], '2012': [16458, 25051], '2013': [16662, 26535], '2014': [16835, 27614], '2015': [15953, 28426], '2016': [15318, 29989], '2017': [14551, 29060], '2018': [10571, 24146], '2019': [46, 523]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhEdJ_P4nhS1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "90c982a0-18b1-446c-a4dd-15305605bedd"
      },
      "source": [
        "#get coauthor\n",
        "word_a=\"Computer network\"\n",
        "word_b=\"Machine learning\"\n",
        "import json\n",
        "from itertools import combinations\n",
        "a=open(\"dblp_papers_v11.txt\",\"r\")\n",
        "b=open(\"coauthor_year_\"+word_a+\"_\"+word_b+\".txt\",'w')\n",
        "count=0\n",
        "for line in a:\n",
        "    try:\n",
        "        c=json.loads(line)\n",
        "        now_authors=[]\n",
        "        for i in (c['authors']):\n",
        "            if(authors.get(i['id'])!=None):\n",
        "              now_authors+=[i['id']]\n",
        "        for i in combinations(now_authors,2):\n",
        "          b.write(i[0]+'\\t'+i[1]+'\\t'+str(c['year'])+'\\n')\n",
        "          count+=1\n",
        "          if count%100000==0:\n",
        "            print(count)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "a.close()\n",
        "b.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000\n",
            "200000\n",
            "300000\n",
            "400000\n",
            "500000\n",
            "600000\n",
            "700000\n",
            "800000\n",
            "900000\n",
            "1000000\n",
            "1100000\n",
            "1200000\n",
            "1300000\n",
            "1400000\n",
            "1500000\n",
            "1600000\n",
            "1700000\n",
            "1800000\n",
            "1900000\n",
            "2000000\n",
            "2100000\n",
            "2200000\n",
            "2300000\n",
            "2400000\n",
            "2500000\n",
            "2600000\n",
            "2700000\n",
            "2800000\n",
            "2900000\n",
            "3000000\n",
            "3100000\n",
            "3200000\n",
            "3300000\n",
            "3400000\n",
            "3500000\n",
            "3600000\n",
            "3700000\n",
            "3800000\n",
            "3900000\n",
            "4000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLz1SZEu-ik9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c3e6f4db-b7e2-4fb2-bbac-20b497d81cb8"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " author_id.txt\t\t\t\t\t GCN_paprmeters.ipynb\n",
            " Brain.npz\t\t\t\t\t layers.py\n",
            " CollegeMsg_transform.txt\t\t\t load.py\n",
            " CollegeMsg.txt\t\t\t\t\t main_SBM_change_label.py\n",
            " DBLP3.npz\t\t\t\t\t models.py\n",
            " DBLP5.npz\t\t\t\t\t __pycache__\n",
            " dblp.ipynb\t\t\t\t\t reddit.npz\n",
            " dblp_label.npy\t\t\t\t\t selfLSTM.py\n",
            "'filter_Computer network_Machine learning.txt'\t utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsyQ1W9Z-ilB"
      },
      "source": [
        "word_a=\"Computer network\"\n",
        "word_b=\"Machine learning\"\n",
        "\n",
        "a=open(\"filter_\"+word_a+\"_\"+word_b+\".txt\",'r')\n",
        "authors_year=dict()\n",
        "for line in a:\n",
        "  split_line=line.split()\n",
        "  if int(split_line[1])==2005:\n",
        "        authors_year[split_line[0]]=1\n",
        "a.close()\n",
        "\n",
        "\n",
        "\n",
        "a=open(\"filter_\"+word_a+\"_\"+word_b+\".txt\",'r')\n",
        "\n",
        "b=open(\"filter_\"+word_a+\"_\"+word_b+\"_2005_\"+\".txt\",'w')  #get author published papers in 2005\n",
        "\n",
        "for line in a:\n",
        "  split_line=line.split()\n",
        "  if authors_year.get(split_line[0])!=None:\n",
        "        if int(split_line[1])>=2005:\n",
        "              b.write(line)\n",
        "\n",
        "b.close()\n",
        "a.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujRIRn08-ilG"
      },
      "source": [
        "word_a=\"Computer network\"\n",
        "word_b=\"Machine learning\"\n",
        "\n",
        "a=open(\"filter_\"+word_a+\"_\"+word_b+\"_2005_\"+\".txt\",'r')\n",
        "authors_year=dict()\n",
        "for line in a:\n",
        "  split_line=line.split()\n",
        "  if int(split_line[1])==2018:\n",
        "        authors_year[split_line[0]]=1\n",
        "a.close()\n",
        "\n",
        "\n",
        "\n",
        "a=open(\"filter_\"+word_a+\"_\"+word_b+\"_2005_\"+\".txt\",'r')\n",
        "\n",
        "b=open(\"filter_\"+word_a+\"_\"+word_b+\"_2005_2018_\"+\".txt\",'w')  #get author published papers in 2005 and 2018\n",
        "\n",
        "for line in a:\n",
        "  split_line=line.split()\n",
        "  if authors_year.get(split_line[0])!=None:\n",
        "        if int(split_line[1])>=2005:\n",
        "              b.write(line)\n",
        "\n",
        "b.close()\n",
        "a.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGPyljfQ-ilJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL4i6C5Q-ilM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a9af2f3b-082d-4328-b36b-a451f1def822"
      },
      "source": [
        "word_a=\"Computer network\"\n",
        "word_b=\"Machine learning\"\n",
        "a=open(\"filter_\"+word_a+\"_\"+word_b+\"_2005_2018_\"+\".txt\",'r')\n",
        "\n",
        "author=None\n",
        "authors=dict()\n",
        "change_author_01=[]\n",
        "change_author_10=[]\n",
        "flag=-1\n",
        "change_author=[]\n",
        "year_count=dict()\n",
        "year_num_count=dict()\n",
        "for i in range(2005,2020):\n",
        "  year_count[str(i)]=[0,0]\n",
        "  year_num_count[str(i)]=[0,0]\n",
        "for line in a:\n",
        "  line=line.split()\n",
        "  if author!=line[0]:\n",
        "    author=line[0]\n",
        "    authors[author]=1\n",
        "    flag=-1\n",
        "  if int(line[2])<int(line[3]):\n",
        "    flag_now=1\n",
        "  elif int(line[2])>int(line[3]):\n",
        "    flag_now=0\n",
        "  else:\n",
        "    flag_now=flag\n",
        "  if flag!=-1:\n",
        "    if flag!=flag_now:\n",
        "      if flag==0:\n",
        "        change_author_01+=[line[0]]\n",
        "        year_count[line[1]][0]+=1\n",
        "      else:\n",
        "        change_author_10+=[line[0]]\n",
        "        year_count[line[1]][1]+=1 #number of changed authors in that area\n",
        "      change_author+=[line[0]]\n",
        "  flag=flag_now\n",
        "  year_num_count[line[1]][flag]+=1 #number of authors in that area\n",
        "a.close()\n",
        "\n",
        "print(len(authors),len(set(change_author)),len(set(change_author_01)),len(set(change_author_10)))\n",
        "print(year_count)\n",
        "print(year_num_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7278 1446 1329 977\n",
            "{'2005': [0, 0], '2006': [83, 77], '2007': [92, 98], '2008': [103, 90], '2009': [94, 90], '2010': [100, 89], '2011': [115, 70], '2012': [116, 75], '2013': [108, 117], '2014': [156, 81], '2015': [127, 116], '2016': [156, 90], '2017': [146, 100], '2018': [307, 154], '2019': [10, 0]}\n",
            "{'2005': [2844, 4434], '2006': [2235, 3004], '2007': [2261, 3121], '2008': [2241, 3029], '2009': [2313, 3160], '2010': [2270, 3191], '2011': [2281, 3227], '2012': [2242, 3267], '2013': [2282, 3326], '2014': [2218, 3390], '2015': [2186, 3402], '2016': [2130, 3595], '2017': [2098, 3616], '2018': [2430, 4848], '2019': [4, 108]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUq1PZSB-ilQ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdvV3l-S-ilS",
        "outputId": "f02c62d0-6ff3-4c06-b67a-03b802682215"
      },
      "source": [
        "#get coauthor\n",
        "word_a=\"Computer network\"\n",
        "word_b=\"Machine learning\"\n",
        "import json\n",
        "from itertools import combinations\n",
        "a=open(\"dblp_papers_v11.txt\",\"r\")\n",
        "b=open(\"coauthor_year_\"+word_a+\"_\"+word_b+\"_2005_2018_\"+\".txt\",'w')\n",
        "count=0\n",
        "for line in a:\n",
        "    try:\n",
        "        c=json.loads(line)\n",
        "        now_authors=[]\n",
        "        for i in (c['authors']):\n",
        "            if(authors.get(i['id'])!=None):\n",
        "              now_authors+=[i['id']]\n",
        "        if 2005<=int(c['year'])<=2018:\n",
        "            for i in combinations(now_authors,2):\n",
        "              b.write(i[0]+'\\t'+i[1]+'\\t'+str(c['year'])+'\\n')\n",
        "              count+=1\n",
        "            if count%100000==0:\n",
        "                print(count)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "a.close()\n",
        "b.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "'year'\n",
            "'year'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62TK79Jx-ilV"
      },
      "source": [
        "a=open('author_id.txt',\"w\")\n",
        "count=0\n",
        "for i in authors:\n",
        "    a.write(i+'\\t'+str(count)+'\\n')\n",
        "    authors[i]=count\n",
        "    count+=1\n",
        "a.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYF__23Z-ilX"
      },
      "source": [
        "import numpy as np\n",
        "L=np.zeros((14,len(authors),len(authors)))\n",
        "a=open(\"coauthor_year_\"+word_a+\"_\"+word_b+\"_2005_2018_\"+\".txt\",'r')\n",
        "for line in a:\n",
        "    line=line.split()\n",
        "    L[int(line[2])-2005][authors[line[0]]][authors[line[1]]]+=1\n",
        "    L[int(line[2])-2005][authors[line[1]]][authors[line[0]]]+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6ZFPWtX-ilc"
      },
      "source": [
        "\n",
        "\n",
        "Labels=np.zeros((len(authors),14,2))\n",
        "a=open(\"filter_\"+word_a+\"_\"+word_b+\"_2005_2018_\"+\".txt\",'r')\n",
        "\n",
        "\n",
        "author=None\n",
        "for line in a:\n",
        "      line=line.split()\n",
        "      if author!=line[0]:\n",
        "        author=line[0]\n",
        "        flag=-1\n",
        "      if int(line[2])<int(line[3]):\n",
        "        flag_now=1\n",
        "      elif int(line[2])>int(line[3]):\n",
        "        flag_now=0\n",
        "      else:\n",
        "        flag_now=flag\n",
        "      if flag_now==-1:\n",
        "        flag_now=1\n",
        "      if authors.get(line[0])!=None:\n",
        "            if 2005<=int(line[1])<=2018:\n",
        "                    Labels[authors[line[0]]][int(line[1])-2005][flag_now]=1\n",
        "      flag=flag_now\n",
        "a.close()\n",
        "\n",
        "np.save(\"dblp_label\",Labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYN_cW7Z-ile"
      },
      "source": [
        "for i in range(len(Labels)):\n",
        "    for t in range(len(Labels[i])):\n",
        "        if Labels[i][t].sum()==0:\n",
        "            Labels[i][t][0]=Labels[i][t-1][0]\n",
        "            Labels[i][t][1]=Labels[i][t-1][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5payoB6Z-ilf"
      },
      "source": [
        "np.save(\"dblp_label\",Labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AygOtrS-ilh"
      },
      "source": [
        "change_num=dict()\n",
        "author_num=dict()\n",
        "for i in range(14):\n",
        "    change_num[i]=[0,0] #1st: change from 0 to 1, 2nd: change from 1 to 0\n",
        "    author_num[i]=[0,0]\n",
        "for i in Labels:\n",
        "    for j in range(len(i)):\n",
        "        author_num[j]+=i[j]\n",
        "        if j>0:\n",
        "            if i[j][0]!=i[j-1][0]:\n",
        "                change_num[j]+=i[j-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9EJNgIj-ilk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a82a1b9d-da5a-41f6-bee5-30864c8463fc"
      },
      "source": [
        "change_num"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [0, 0],\n",
              " 1: array([ 83., 105.]),\n",
              " 2: array([ 92., 110.]),\n",
              " 3: array([103.,  91.]),\n",
              " 4: array([94., 91.]),\n",
              " 5: array([100.,  89.]),\n",
              " 6: array([115.,  70.]),\n",
              " 7: array([116.,  75.]),\n",
              " 8: array([108., 117.]),\n",
              " 9: array([156.,  81.]),\n",
              " 10: array([127., 116.]),\n",
              " 11: array([156.,  90.]),\n",
              " 12: array([146., 100.]),\n",
              " 13: array([307., 154.])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCUWKZbk-iln",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "ac30c722-75ef-474c-9a8e-20266ad71177"
      },
      "source": [
        "author_num"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: array([2844., 4434.]),\n",
              " 1: array([2866., 4412.]),\n",
              " 2: array([2884., 4394.]),\n",
              " 3: array([2872., 4406.]),\n",
              " 4: array([2869., 4409.]),\n",
              " 5: array([2858., 4420.]),\n",
              " 6: array([2813., 4465.]),\n",
              " 7: array([2772., 4506.]),\n",
              " 8: array([2781., 4497.]),\n",
              " 9: array([2706., 4572.]),\n",
              " 10: array([2695., 4583.]),\n",
              " 11: array([2629., 4649.]),\n",
              " 12: array([2583., 4695.]),\n",
              " 13: array([2430., 4848.])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2QwmDLZ-ilq"
      },
      "source": [
        "np.savez_compressed('DBLPE', adjs=L, labels=Labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWkgpGcXBFSJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "5ef22cae-ab57-44e8-c350-ab54788633fe"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " author_id.txt\n",
            " Brain.npz\n",
            "'coauthor_year_Computer network_Machine learning_2005_2018_.txt'\n",
            "'coauthor_year_Computer network_Machine learning.txt'\n",
            " CollegeMsg_transform.txt\n",
            " CollegeMsg.txt\n",
            " DBLP3.npz\n",
            " DBLP5.npz\n",
            " DBLPE.npz\n",
            " dblp.ipynb\n",
            " dblp_label.npy\n",
            "'filter_Computer network_Machine learning_2005_2018_.txt'\n",
            "'filter_Computer network_Machine learning_2005_.txt'\n",
            "'filter_Computer network_Machine learning.txt'\n",
            " GCN_paprmeters.ipynb\n",
            " layers.py\n",
            " load.py\n",
            " main_SBM_change_label.py\n",
            " models.py\n",
            " __pycache__\n",
            " reddit.npz\n",
            " selfLSTM.py\n",
            " utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}